# Trabajo UT6 - Clasificaci√≥n

Este proyecto es un an√°lisis completo de modelos de clasificaci√≥n binaria aplicados al dataset de diagn√≥stico de c√°ncer de mama.
***Por Borja R.O., Curso especializaci√≥n IA & Big Data***

## Introducci√≥n

## Contenido del Notebook

El video explicativo [se puede encontrar aqu√≠](https://gofile.me/7rLu1/t9Invn81o) 

El notebook, ejecutable en Google Colab, mediante [este enlace](https://colab.research.google.com/drive/18J4-G_rSWPHgTGh4XyY8TLhkGsdnvanM?usp=sharing) incluye:

### 1. Preprocesado de Datos

- **Importaci√≥n del dataset:** `sklearn.datasets.load_breast_cancer` (569 muestras, 30 features)
- **Manejo de valores missing:** Demostraci√≥n de `SimpleImputer` (el dataset no contiene missing)
- **Codificaci√≥n de variables categ√≥ricas:** 
  - Label Encoding para variables categ√≥ricas binarias
  - Ordinal Encoding para variables ordinales
  - One-Hot Encoding con `get_dummies()`
  - **Evitar la trampa de las variables dummy:** Uso de `drop_first=True` para eliminar multicolinealidad perfecta
- **Separaci√≥n en conjuntos train/test:** 80% entrenamiento, 20% test con estratificaci√≥n
- **Estandarizaci√≥n de caracter√≠sticas:** Escalado a media=0, desviaci√≥n=1 con `StandardScaler`

### 2. An√°lisis Exploratorio de Datos (EDA)

**üß© Bloque 1 ‚Äì Matriz de Correlaci√≥n (Heatmap)**
- Visualizaci√≥n de correlaciones entre los 30 features del dataset
- Identifica features altamente correlacionadas (r > 0.9)
- Ejemplo: `mean radius`, `mean perimeter` y `mean area` miden esencialmente lo mismo (tama√±o del tumor)

**üß© Bloque 2 ‚Äì Eliminaci√≥n de Features Redundantes**
- Elimina columnas con correlaci√≥n > 0.9 para reducir redundancia
- Reduce de 30 a 16 features sin perder informaci√≥n relevante
- Mejora la interpretabilidad y reduce overfitting en modelos lineales

**üß© Bloque 3 ‚Äì Pairplot**
- Diagonal: Distribuciones individuales de features
- Fuera diagonal: Relaciones entre pares de variables discriminadas por clase
- Colores: Rojo (maligno) vs Azul (benigno)

**üß© Bloque 4 ‚Äì Correlaci√≥n con Variable Target**
- Identifica las variables m√°s discriminativas para la clasificaci√≥n
- Features de tama√±o y textura del tumor muestran mayor correlaci√≥n con el diagn√≥stico

**Conclusi√≥n EDA:** Los datos presentan separabilidad lineal razonable, justificando el √©xito de modelos lineales en este problema.

### 3. Modelos de Clasificaci√≥n Aplicados

#### 3.1 Regresi√≥n Log√≠stica
Modelo lineal que estima la probabilidad de pertenencia a una clase mediante la funci√≥n sigmoide. Interpretable y eficiente.

#### 3.2 K-Vecinos Cercanos (KNN)
Algoritmo basado en instancias: clasifica seg√∫n la clase mayoritaria de los k=5 vecinos m√°s cercanos. No param√©trico.

#### 3.3 M√°quinas de Soporte Vectorial (SVM)
Busca el hiperplano que maximiza el margen entre clases.
- **Kernel Lineal:** Frontera de decisi√≥n lineal
- **Kernel RBF:** Captura relaciones no lineales mediante transformaci√≥n a espacio de mayor dimensi√≥n

#### 3.4 Naive Bayes (Gaussian)
Aplica el teorema de Bayes asumiendo independencia entre features. R√°pido y efectivo en datos de alta dimensi√≥n.

#### 3.5 √Årbol de Decisi√≥n
Divide el espacio de features mediante reglas if/else jer√°rquicas. Interpretable pero propenso al overfitting.

#### 3.6 Bosque Aleatorio (Random Forest)
Ensemble de m√∫ltiples √°rboles de decisi√≥n entrenados con subconjuntos aleatorios. Mitiga el overfitting del √°rbol individual.

### 4. Evaluaci√≥n y Comparaci√≥n

#### 4.1 Detecci√≥n de Overfitting
Comparativa de accuracy en train vs test:
- **√Årboles de Decisi√≥n:** Mayor diferencia (overfitting claro)
- **Modelos Lineales:** Mejor generalizaci√≥n
- **Random Forest:** Mitiga el overfitting respecto a √°rbol individual

#### 4.2 M√©tricas de Evaluaci√≥n (en conjunto test)

| M√©trica | Descripci√≥n |
|---------|-------------|
| **Accuracy** | Proporci√≥n de predicciones correctas |
| **Precision** | Entre los predichos positivos, cu√°ntos son realmente positivos |
| **Sensitivity (Recall)** | Entre los casos reales positivos, cu√°ntos detectamos |
| **Specificity** | Entre los casos reales negativos, cu√°ntos detectamos correctamente |
| **AUC (Area Under Curve)** | M√©trica integral de la curva ROC (0.5=aleatorio, 1=perfecto) |

#### 4.3 Matrices de Confusi√≥n Visualizadas
Desglose de predicciones correctas (TP, TN) e incorrectas (FP, FN) para cada modelo.

#### 4.4 Curvas ROC y AUC
- Gr√°ficas que muestran el trade-off entre sensibilidad y especificidad
- Modelos: Regresi√≥n Log√≠stica y SVM obtienen las mejores curvas ROC
- Todos los modelos superan la l√≠nea aleatoria (AUC > 0.5)

#### 4.5 Validaci√≥n Cruzada (5-fold)
Valida la estabilidad del modelo mediante validaci√≥n cruzada en el conjunto de entrenamiento.
- Modelos con menor varianza entre folds son m√°s fiables
- Confirma que los resultados no son producto del azar en la partici√≥n train/test

#### 4.6 Conclusiones de la Evaluaci√≥n

**Mejores modelos:** 
- Regresi√≥n Log√≠stica y SVM obtienen los mejores resultados en AUC y accuracy
- El dataset es razonablemente separable de forma lineal

**Overfitting:**
- √Årbol de Decisi√≥n: overfitting claro (accuracy train ~99% vs test inferior)
- Random Forest: mitiga significativamente el overfitting
- Modelos lineales: mejor generalizaci√≥n

**Naive Bayes:**
- Rendimiento inferior: la asunci√≥n de independencia entre features no se cumple
- El dataset contiene features altamente correlacionadas

### 5. GridSearch - Optimizaci√≥n Autom√°tica de Hiperpar√°metros

`GridSearchCV` prueba sistem√°ticamente todas las combinaciones de hiperpar√°metros definidas y selecciona la mejor mediante validaci√≥n cruzada.

**Modelos optimizados:**
- **Logistic Regression:** Par√°metro C (regularizaci√≥n) y solver
- **SVM:** C (regularizaci√≥n), kernel (lineal/rbf), gamma
- **Random Forest:** n_estimators (n√∫mero de √°rboles), max_depth (profundidad m√°xima), criterion (gini/entropy)

**Conclusi√≥n GridSearch:** La optimizaci√≥n autom√°tica afina los hiperpar√°metros mejorando ligeramente los resultados respecto a valores por defecto.

## Dataset

**breast_cancer (Breast Cancer Wisconsin):**
- 569 muestras
- 30 caracter√≠sticas cuantitativas (mediciones de c√©lulas cancerosas)
- Variable target binaria: 0=Maligno, 1=Benigno
- Fuente: `sklearn.datasets.load_breast_cancer()`
- Referencia: https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset

## Objetivo

Comparar el rendimiento de diferentes algoritmos de clasificaci√≥n binaria y seleccionar el mejor modelo basado en:
- Accuracy, Precision, Recall, Specificity
- AUC y curvas ROC
- Robustez ante overfitting
- Validaci√≥n cruzada

## Conclusiones Generales

1. **Preprocesado:** Se demostraron todas las t√©cnicas de preprocesado (manejo de missing, codificaci√≥n categ√≥rica con evitar trampa de dummies, estandarizaci√≥n).

2. **EDA:** Identific√≥ features altamente correlacionadas y su relaci√≥n con el target, informando decisiones de modelado.

3. **Modelos:** Se aplicaron 7 modelos de clasificaci√≥n. Los modelos lineales (Regresi√≥n Log√≠stica, SVM) funcionan muy bien en este dataset de separabilidad linear.

4. **Overfitting:** El √°rbol de decisi√≥n es el m√°s propenso; Random Forest lo reduce significativamente mediante ensemble.

5. **Evaluaci√≥n:** Curvas ROC y validaci√≥n cruzada confirman que los modelos son robustos y generalizan bien.

6. **Optimizaci√≥n:** GridSearch confirma y mejora ligeramente los resultados mediante b√∫squeda sistem√°tica de hiperpar√°metros.

---

**Autor:** Borja Ramos
**Asignatura:** Sistemas de Aprendizaje Autom√°tico (SAA)  
**Unidad Tem√°tica:** UT6 - Clasificaci√≥n
